{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amazn1234/CS470-Final-Project/blob/main/AI470_Final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "1. load csv file (panda, numpy)\n",
        "2. split dataset. Example code:()\n",
        "   ```\n",
        "   random.shuffle(data) # change if you are using pandas dataframe\n",
        "   training = data[:int(len(data)*0.8)]\n",
        "   test = data[int(len(data)*0.8):]\n",
        "\n",
        "   fold5 = KFold(5) # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
        "   for train_idx, val_idx in fold5.split(training):\n",
        "      sub_val = training[val_idx]\n",
        "      sub_train = training[train_idx]\n",
        "      clf = model(sub_train, sub_val, ...) # training the model, and evaluate it on validation dataset\n",
        "      performance(clf, test) # test the model on test dataset\n",
        "   ```"
      ],
      "metadata": {
        "id": "uxgBX0YXu1du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#upload dataset\n",
        "fileName = 'spambase.csv'\n",
        "\n",
        "#Avoid having to upload file at every runtime\n",
        "if not os.path.exists(fileName):\n",
        "    #Upload the file if it doesn't exist\n",
        "    uploaded = files.upload()\n",
        "    #Save the uploaded file to avoid future uploads\n",
        "    for name, data in uploaded.items():\n",
        "        with open(fileName, 'wb') as f:\n",
        "            f.write(data)\n",
        "\n",
        "#Load the CSV file into Pandas\n",
        "data = pd.read_csv(fileName)\n",
        "\n",
        "#Remove attributes that are not related to word (the last four attributes)\n",
        "columnsToDrop = ['capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'char_freq_#']\n",
        "\n",
        "if set(columnsToDrop).issubset(data.columns):\n",
        "    data.drop(columnsToDrop, axis=1, inplace=True)\n",
        "    print(\"Columns dropped successfully.\")\n",
        "else:\n",
        "    print(\"Columns not found in the DataFrame.\")\n",
        "\n",
        "#Shuffle the data\n",
        "dataShuffled = data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "#Set feature/target variables\n",
        "#featuresVec=(dataShuffled.iloc[:,:-1])\n",
        "#resultVar=(dataShuffled.iloc[:,-1])\n",
        "\n",
        "#Split the dataset and set feature/target variables (80/20 split)\n",
        "features_train, features_test, result_train, result_test = train_test_split(dataShuffled.iloc[:, :-1], dataShuffled.iloc[:, -1], test_size=0.2)\n",
        "\n",
        "#print(\"features_train:\", features_train)\n",
        "#print(\"features_test:\", features_test)\n",
        "#print(\"result_train:\", result_train)\n",
        "#print(\"result_test:\", result_test)\n"
      ],
      "metadata": {
        "id": "Bt0pDqz_kqhy",
        "outputId": "71c000ce-5eaa-4bb8-cc06-197df5bb2681",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns dropped successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive bayes\n",
        "\n",
        "1. model learning:\n",
        "\n",
        "   Note:\n",
        "\n",
        "   features: remove attributes that is not related to word (the last four attributes)\n",
        "\n",
        "   labels: the last column\n",
        "\n",
        "   count P(c) -> how many samples are positive, and how many are negtive\n",
        "\n",
        "   if freq_word>0, then this word exists. You could use this to calculate P(a|c) -> for each class, what is the prob of each word\n",
        "\n",
        "   remember to use laplace smoothing.\n",
        "\n",
        "2. model evaluation (on val dataset -> performance(model, val)):\n",
        "   \n",
        "   for each new sample, $\\prod{P(a|c)}P(c)$ if word is in the email(freq_word > 0); and find the maximum class\n",
        "   \n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "FXyRfd35yRPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "#Find chance of being spam\n",
        "priorSpam = len(dataShuffled[dataShuffled['spam'] == 1]) / len(dataShuffled)\n",
        "priorNotSpam = 1 - priorSpam\n",
        "\n",
        "#print(\"percentage of emails that are spam in the dataset: \", priorSpam)\n",
        "\n",
        "#Calculate likelihood of spam\n",
        "likelihoodSpamArr = {}\n",
        "likelihoodNotSpamArr = {}\n",
        "\n",
        "for col in features_train.columns:\n",
        "    likelihoodSpamArr[col] = {}\n",
        "    likelihoodNotSpamArr[col] = {}\n",
        "\n",
        "    for val in dataShuffled[col].unique():\n",
        "        likelihoodSpamArr[col][val] = len(dataShuffled[(dataShuffled['spam'] == 1) & (features_train[col] == val)]) / len(dataShuffled[dataShuffled['spam'] == 1])\n",
        "        likelihoodNotSpamArr[col][val] = len(dataShuffled[(dataShuffled['spam'] == 0) & (features_train[col] == val)]) / len(dataShuffled[dataShuffled['spam'] == 0])\n",
        "\n",
        "\n",
        "#Predict class of a sample\n",
        "def predict(sample, likelihoodSpamArr, likelihoodNotSpamArr, priorSpam, priorNotSpam, threshold=0.5):\n",
        "\n",
        "    #Calculate class probabilities for each feature\n",
        "    for col, val in sample.items():\n",
        "        if col != 'spam':  #Skip the target column\n",
        "            #Calculate likelihood using Laplace smoothing\n",
        "            priorSpam *= likelihoodSpamArr[col].get(val, 0.05)\n",
        "            priorNotSpam *= likelihoodNotSpamArr[col].get(val, 0.05)\n",
        "\n",
        "    #Make prediction based on the class probability and threshold\n",
        "    if priorSpam > threshold:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "#Test the model\n",
        "predictions = []\n",
        "for index, sample in features_test.iterrows():\n",
        "    #Predict the class\n",
        "    prediction = predict(sample, likelihoodSpamArr, likelihoodNotSpamArr, priorSpam, priorNotSpam)\n",
        "    predictions.append(prediction)\n",
        "\n",
        "\n",
        "############################\n",
        "#Performance Testing\n",
        "############################\n",
        "\n",
        "#Calculate accuracy\n",
        "def CalculateAccuracy(predictions, trueLabelArr):\n",
        "  correctPredictions = sum(predictions == trueLabelArr)\n",
        "\n",
        "  totalSamples = len(trueLabelArr)\n",
        "\n",
        "  accuracy = correctPredictions / totalSamples\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "#Print Accuracy\n",
        "accuracy = CalculateAccuracy(result_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "#find true positives and false positives\n",
        "def FindTPAndFP(guessArr, trueLabel):\n",
        "    truePositives, falsePositives = 0, 0\n",
        "\n",
        "    #loop through each prediction and true result\n",
        "    for pred, trueLabel in zip(guessArr, trueLabel):\n",
        "        if pred == 1 and trueLabel == 1:\n",
        "            truePositives += 1\n",
        "        elif pred == 1 and trueLabel == 0:\n",
        "            falsePositives += 1\n",
        "\n",
        "    return truePositives, falsePositives\n",
        "\n",
        "def performance(predictions, trueLabels):\n",
        "    #Calculate AUC score\n",
        "    aucScore = roc_auc_score(trueLabels, predictions)\n",
        "\n",
        "    return aucScore\n",
        "\n",
        "truePositives, falsePositives = FindTPAndFP(predictions, result_test)\n",
        "aucScore = performance(predictions, result_test)\n",
        "print(\"False Positives:\", falsePositives)\n",
        "print(\"True Positives:\", truePositives)\n",
        "print(\"Area Under the Curve (AUC):\", aucScore)"
      ],
      "metadata": {
        "id": "Sn0SBgrEbi_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6f856c-a816-4aac-bdcf-f8d2d5051ebc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "percentage of emails that are spam in the dataset:  0.39404477287546186\n",
            "Accuracy: 0.6156351791530945\n",
            "False Positives: 0\n",
            "True Positives: 0\n",
            "Area Under the Curve (AUC): 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN\n",
        "1. model learning: None\n",
        "\n",
        "2. model evaluation(on val dataset): You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "\n",
        "   ```\n",
        "   Note:\n",
        "   parallel programing\n",
        "   numpy.cos() to calcuate the similarity\n",
        "   ```"
      ],
      "metadata": {
        "id": "5jRvHTlW0DYA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HKOOxj8dhUct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR\n",
        "\n",
        "1. model learning: You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "    \n",
        "    $y = sigmoid(MX)$\n",
        "\n",
        "step 1: add one more column (all value is 1) in X -> X' = np.c_[np.ones((len(X), 1)), X]\n",
        "\n",
        "step 2:vector M = np.random.randn(len(X[0])+1, 1);\n",
        "\n",
        "key formula for step 3 (Note: n is the size of the TRAINING dataset; $cdot$ is dot production ):\n",
        "\n",
        "1. $pred_y = sigmoid(M\\cdot X')$\n",
        "\n",
        "2. $loss = -\\sum(y\\cdot log(pred_y)+(1-y)\\cdot log(1-pred_y))/n$\n",
        "\n",
        "3. $gm=X'\\cdot (pred_y - y)*2/n$\n",
        "\n",
        "Step 3 example code:\n",
        "   ```\n",
        "   #Step 3: performing gradient descent on whole dataset:\n",
        "   best_model = M\n",
        "   best_performace = 0\n",
        "   for i in range(epoch):\n",
        "     pred_y = ...\n",
        "     gm = ...\n",
        "     _p = performace(model, val)\n",
        "     if _p > best_performance:\n",
        "        best_model = M\n",
        "        best_performance = _p\n",
        "     M = M - learning_rate*gm\n",
        "   ```\n",
        "\n",
        "2. model evaluation(on val dataset):\n",
        "  \n",
        "   calculate pred_y, if more than 0.5, then the predicted label is 1."
      ],
      "metadata": {
        "id": "OUzUupva0Fxw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ckr2uWvQhVWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html"
      ],
      "metadata": {
        "id": "mAssSW_I0GvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def performance(model, data):\n",
        "  print(\"result:\")\n",
        "  return result"
      ],
      "metadata": {
        "id": "e0MQ0eo0MnmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}